{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d923c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T17:47:38.293988Z",
     "start_time": "2023-04-27T17:47:37.537822Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def get_second(time_str):\n",
    "    segment = time_str.split(' ')\n",
    "    second = 0    \n",
    "    for i in segment:\n",
    "        if i[-1] == 's':\n",
    "            second += int(i[:-1])\n",
    "        elif i[-1] == 'm':\n",
    "            second += int(i[:-1]) * 60\n",
    "        elif i[-1] == 'h':\n",
    "            second += int(i[:-1]) * 60 * 60\n",
    "        elif i[-1] == 'd':\n",
    "            second += int(i[:-1]) * 60 * 60 * 24\n",
    "        else:\n",
    "            print(time_str)\n",
    "    return second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba7a3d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T17:47:55.011019Z",
     "start_time": "2023-04-27T17:47:38.296057Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/raw_dataset.csv',parse_dates=['created_at'])\n",
    "df['is_bot'] = df['is_bot'].astype(bool)\n",
    "df.sort_values(by=['created_at'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71de0e12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T17:58:15.112514Z",
     "start_time": "2023-04-27T17:47:55.022901Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577fbdaf632d4a1bb18f12653f95d633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create boxplot for additional cost\n",
    "\n",
    "# Recheck [waiting time / code review time / computation time / propotion (waiting time in code review time)]\n",
    "# Overall [waiting time / code review time / computation time]\n",
    "\n",
    "tqdm.pandas()\n",
    "output = dict()\n",
    "\n",
    "df.sort_values(by=['created_at'], inplace=True)\n",
    "for key, group in tqdm(df.groupby(['change_id','revision_number'])):\n",
    "    \n",
    "    change_id , revision_number = key\n",
    "    build_fail, recheck, build_fail_then_recheck = False, False, False \n",
    "    final_status = dict()\n",
    "    prev_status = dict()\n",
    "    computation_time = 0\n",
    "    \n",
    "    total_max_time = 0\n",
    "    max_time = 0\n",
    "\n",
    "    dict_bot = {}\n",
    "    rnd = 0\n",
    "    \n",
    "    start_time = ''\n",
    "    end_time = ''\n",
    "\n",
    "    recheck_count = 0\n",
    "    \n",
    "    for ind,col in group.iterrows():\n",
    "        \n",
    "        time = col['created_at']\n",
    "        \n",
    "        if not start_time:\n",
    "            start_time = time\n",
    "            \n",
    "        if not end_time or time > end_time:\n",
    "            end_time = time\n",
    "        \n",
    "        #start loop if build fail is found\n",
    "        if not build_fail and col['is_bot'] and 'build failed' in col['message'].lower():\n",
    "            build_fail = True\n",
    "            \n",
    "        if not build_fail:\n",
    "            continue\n",
    "                                                \n",
    "        if col['is_bot']:\n",
    "            try:\n",
    "                patch_fail = False\n",
    "                build = re.findall(r'((?:merge|build) (?:succeeded|failed))',col['message'],re.IGNORECASE)\n",
    "                bot = re.findall(r'((?:success|failure|aborted) in(?: \\w+?)*s)',col['message'],re.IGNORECASE)\n",
    "                \n",
    "                if any('fail' in b.lower() for b in build): #or any('fail' in b.lower() for b in bot):\n",
    "                    patch_fail = True\n",
    "                elif any('abort' in b.lower() for b in build): #or any('abort' in b.lower() for b in bot):\n",
    "                    patch_fail = True\n",
    "                \n",
    "                if build_fail and recheck:                \n",
    "                    bot_time = 0\n",
    "                    for i in bot:\n",
    "                        bot_time += get_second(i.split(' in ')[1])\n",
    "                        \n",
    "                        if max_time < get_second(i.split(' in ')[1]):\n",
    "                            max_time = get_second(i.split(' in ')[1])\n",
    "                        \n",
    "                    computation_time += bot_time\n",
    "            except:\n",
    "                pass\n",
    "  \n",
    "            if rnd not in dict_bot:\n",
    "                dict_bot[rnd] = dict()\n",
    "\n",
    "            if col['username'] not in dict_bot[rnd]:\n",
    "                dict_bot[rnd][col['username']] = ''\n",
    "\n",
    "            \n",
    "            if dict_bot[rnd][col['username']] == 'failure':\n",
    "                final_status[col['username']] = 'failure'\n",
    "            else:\n",
    "                \n",
    "                if patch_fail:\n",
    "                    dict_bot[rnd][col['username']] = 'failure'\n",
    "                else:\n",
    "                    dict_bot[rnd][col['username']] = 'success'\n",
    "\n",
    "                final_status[col['username']] = 'failure' if patch_fail else 'success'\n",
    "\n",
    "\n",
    "        \n",
    "        if 'recheck' in col['message'].lower() and col['is_bot'] == False:\n",
    "            recheck = True\n",
    "            rnd += 1\n",
    "            \n",
    "            if len(final_status) > 0:\n",
    "                prev_status = final_status\n",
    "            final_status = dict()\n",
    "            \n",
    "            total_max_time += max_time\n",
    "            max_time = 0\n",
    "            \n",
    "            if build_fail:\n",
    "                build_fail_then_recheck = True\n",
    "            \n",
    "            recheck_count += 1\n",
    "            \n",
    "    total_max_time += max_time\n",
    "    if build_fail_then_recheck:\n",
    "        \n",
    "        status = ''\n",
    "        \n",
    "        if len(final_status) == 0:\n",
    "            final_status = prev_status\n",
    "        \n",
    "        for username in final_status:\n",
    "            if status == 'failure':\n",
    "                continue\n",
    "            if final_status[username] == 'failure':\n",
    "                status = 'failure'\n",
    "            if final_status[username] == '':\n",
    "                status = ''\n",
    "            if final_status[username] == 'success':\n",
    "                status = 'success'\n",
    "        \n",
    "        output[key] = {'computation_time': computation_time,'status': status, 'bot':dict_bot, 'waiting_time':total_max_time, 'code_review_time': (end_time - start_time).total_seconds(), 'recheck_count': recheck_count}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d842a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T18:05:37.313511Z",
     "start_time": "2023-04-27T17:58:15.117007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa39a98e9294f5cb8bcbfe72de1cde8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create boxplot for additional cost\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "patch_output = dict()\n",
    "\n",
    "df.sort_values(by=['created_at'], inplace=True)\n",
    "for key, group in tqdm(df.groupby(['change_id','revision_number'])):\n",
    "    \n",
    "    if key in output:\n",
    "        continue\n",
    "    \n",
    "    change_id , revision_number = key\n",
    "\n",
    "    computation_time = 0 \n",
    "    \n",
    "    recheck = False\n",
    "    \n",
    "    start_time = ''\n",
    "    end_time = ''\n",
    "\n",
    "    max_time = 0\n",
    "    \n",
    "    for ind,col in group.iterrows():\n",
    "        \n",
    "        time = col['created_at']\n",
    "        \n",
    "        if not start_time:\n",
    "            start_time = time\n",
    "            \n",
    "        if not end_time or time > end_time:\n",
    "            end_time = time\n",
    "        \n",
    "        if col['is_bot']:\n",
    "            try:\n",
    "                patch_fail = False\n",
    "                build = re.findall(r'((?:merge|build) (?:succeeded|failed))',col['message'],re.IGNORECASE)\n",
    "                bot = re.findall(r'((?:success|failure|aborted) in(?: \\w+?)*s)',col['message'],re.IGNORECASE)\n",
    "                \n",
    "                if any('fail' in b.lower() for b in build): #or any('fail' in b.lower() for b in bot):\n",
    "                    patch_fail = True\n",
    "                elif any('abort' in b.lower() for b in build): #or any('abort' in b.lower() for b in bot):\n",
    "                    patch_fail = True\n",
    "                \n",
    "                bot_time = 0\n",
    "                for i in bot:\n",
    "                    bot_time += get_second(i.split(' in ')[1])\n",
    "\n",
    "                    if max_time < get_second(i.split(' in ')[1]):\n",
    "                        max_time = get_second(i.split(' in ')[1])\n",
    "\n",
    "                computation_time += bot_time\n",
    "            except:\n",
    "                pass\n",
    "          \n",
    "        if 'recheck' in col['message'].lower() and col['is_bot'] == False:\n",
    "            \n",
    "            recheck = True\n",
    "            break\n",
    "            \n",
    "    if recheck:\n",
    "        continue\n",
    "\n",
    "    patch_output[key] = {'computation_time': computation_time, 'waiting_time':max_time, 'code_review_time': (end_time - start_time).total_seconds()}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5fd2c70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T18:05:37.716491Z",
     "start_time": "2023-04-27T18:05:37.317198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0642ec21f3614babba680d3f4e6f537b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I9a5b48d58ff9a1ba651468b818cc669e1ca099ff', 3) 116\n",
      "('Ibea13629fafc40ffd9ba64a318dcfd691c88a1dc', 1) 175\n"
     ]
    }
   ],
   "source": [
    "output_tup = list()\n",
    "\n",
    "dropped_case, added_case, replaced_case = 0,0,0\n",
    "same_case_1, dropped_case_1, added_case_1, replaced_case_1 = 0,0,0,0\n",
    "\n",
    "for key in tqdm(output):\n",
    "    \n",
    "#     proportion = round(output[key]['waiting_time'] * 100 / output[key]['code_review_time'] ,2)\n",
    "\n",
    "    computation_time = output[key]['computation_time']\n",
    "    waiting_time = output[key]['waiting_time']\n",
    "    code_review_time = output[key]['code_review_time']\n",
    "    status = output[key]['status']\n",
    "    \n",
    "    bots = output[key]['bot']\n",
    "    first_bot = bots[0]\n",
    "    last_bot = bots[list(bots.keys())[-1]]\n",
    "    \n",
    "    \n",
    "    if len(bots) >= 100:\n",
    "        print(key, len(bots))\n",
    "    \n",
    "    # scenario \n",
    "    \n",
    "    # scenario #1 [Changed outcome] Justifiable\n",
    "    # scenario #2 [Changed outcome] Repeated builds\n",
    "    # scenario #3 [No Change] Single recheck\n",
    "    # scenario #4 [No Change] Multiple recheck\n",
    "\n",
    "    if status == 'success' and len(bots) == 2:\n",
    "        scenario = 1\n",
    "    elif status == 'success' and len(bots) != 2:\n",
    "        scenario = 2\n",
    "    elif status == 'failure' and len(bots) == 2:\n",
    "        scenario = 3\n",
    "    elif status == 'failure' and len(bots) != 2:\n",
    "        scenario = 4\n",
    "    else:\n",
    "        print(\"should not be here\", key)\n",
    "    \n",
    "    bot_modify = 0\n",
    "    \n",
    "    # l_key union f_key\n",
    "    f_u_l = set(first_bot.keys()).union(set(last_bot.keys()))\n",
    "    # cehck if L == F\n",
    "    if set(first_bot.keys()) == set(last_bot.keys()):\n",
    "        bot_modify = 'same bot'\n",
    "    # check if L in F, FuL == F [dropped case]\n",
    "    elif set(first_bot.keys()) == f_u_l:\n",
    "        bot_modify = 'drop bot'\n",
    "    # check if F in L, FuL == L [added case]\n",
    "    elif set(last_bot.keys()) == f_u_l:\n",
    "        bot_modify = 'add bot'\n",
    "    # replace case\n",
    "    else:\n",
    "        bot_modify = 'replace bot'\n",
    "    \n",
    "    output_tup.append((key, scenario, bot_modify, status, computation_time, waiting_time, code_review_time))\n",
    "recheck_df = pd.DataFrame(output_tup, columns=['key', 'scenario', 'bot_modify', 'status', 'computation_time', 'waiting_time', 'code_review_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc6b241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T15:50:07.662592Z",
     "start_time": "2023-04-10T15:46:24.303043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54b7e0548ab47aca28b4990d8524469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## - Break down result from table 3,4 for multiple recheck with change outcome \n",
    "##   to the first chunk unchange outcome[x hours] change outcome[x hours]\n",
    "\n",
    "scenario_2_df = recheck_df[recheck_df['scenario'] == 2].copy()\n",
    "scenario_2_df.reset_index(inplace=True)\n",
    "scenario_2_keys = scenario_2_df['key'].tolist()\n",
    "\n",
    "for key, group in tqdm(df.groupby(['change_id','revision_number'])):    \n",
    "    \n",
    "    if key not in scenario_2_keys:\n",
    "        continue\n",
    "    \n",
    "    scenario_2_index = scenario_2_keys.index(key)\n",
    "    \n",
    "    computation_time = 0\n",
    "    max_time = 0\n",
    "    prev_computation_time = 0\n",
    "    prev_max_time = 0\n",
    "\n",
    "    for ind,col in group.iterrows():\n",
    "        \n",
    "        #start loop if build fail is found\n",
    "        if not build_fail and col['is_bot'] and 'build' in col['message'].lower():\n",
    "            build_fail = True\n",
    "            \n",
    "        if not build_fail:\n",
    "            continue\n",
    "                                                \n",
    "        if col['is_bot']:\n",
    "            try:\n",
    "                patch_fail = False\n",
    "                build = re.findall(r'((?:merge|build) (?:succeeded|failed))',col['message'],re.IGNORECASE)\n",
    "                bot = re.findall(r'((?:success|failure|aborted) in(?: \\w+?)*s)',col['message'],re.IGNORECASE)\n",
    "                \n",
    "                if any('fail' in b.lower() for b in build): #or any('fail' in b.lower() for b in bot):\n",
    "                    patch_fail = True\n",
    "                elif any('abort' in b.lower() for b in build): #or any('abort' in b.lower() for b in bot):\n",
    "                    patch_fail = True\n",
    "                \n",
    "                if build_fail and recheck:                \n",
    "                    bot_time = 0\n",
    "                    for i in bot:\n",
    "                        bot_time += get_second(i.split(' in ')[1])\n",
    "                        \n",
    "                        if max_time < get_second(i.split(' in ')[1]):\n",
    "                            max_time = get_second(i.split(' in ')[1])\n",
    "                        \n",
    "                    computation_time += bot_time\n",
    "            except:\n",
    "                pass\n",
    "  \n",
    "        \n",
    "        if 'recheck' in col['message'].lower() and col['is_bot'] == False:\n",
    "            recheck = True\n",
    "            if computation_time and max_time:\n",
    "                prev_computation_time = computation_time\n",
    "                prev_max_time = max_time\n",
    "            \n",
    "            max_time = 0\n",
    "            computation_time = 0\n",
    "            \n",
    "    if max_time == 0:\n",
    "        max_time = prev_max_time\n",
    "        computation_time = prev_computation_time\n",
    "        \n",
    "    scenario_2_df.at[scenario_2_index, 'last_recheck_computation_time'] = computation_time\n",
    "    scenario_2_df.at[scenario_2_index, 'last_recheck_waiting_time'] = max_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56aaca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T15:50:07.697042Z",
     "start_time": "2023-04-10T15:50:07.689412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6517\n",
      "total    computation_time: 22836 days, 14:33:00\n",
      "accumerate computation_time before change CI outcome: 15888 days, 18:26:55, (70%)\n",
      "last recheck computation_time: 6947 days, 20:06:05, (30%)\n",
      "-------------\n",
      "total    waiting_time: 1890 days, 4:30:25\n",
      "accumerate waiting_time before change CI outcome: 1361 days, 14:24:14, (72%)\n",
      "last recheck waiting_time: 528 days, 14:06:11, (28%)\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "print(scenario_2_df.shape[0])\n",
    "\n",
    "for i in ['computation_time', 'waiting_time']:\n",
    "    total_time = int(scenario_2_df[i].sum())\n",
    "    last_time = int(scenario_2_df[\"last_recheck_\" + i].sum())\n",
    "    accu_time = total_time - last_time\n",
    "    print(f'total    {i}: {timedelta(seconds=total_time)}')\n",
    "    print(f'accumerate {i} before change CI outcome: {timedelta(seconds=accu_time)}, ({round(accu_time * 100 / total_time)}%)')\n",
    "    print(f'last recheck {i}: {timedelta(seconds=last_time)}, ({round(last_time * 100 / total_time)}%)')\n",
    "    print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0846e9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T17:59:18.829054Z",
     "start_time": "2023-04-10T17:36:24.155997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc27f57c1a3c4e85928096f45420ed32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## As suggested in the Intro, I think we should not compare against a normal code review for \n",
    "## Observation 7 and 8. However, we can calculate the proportion of waiting time to the total review time \n",
    "## per code review. Then, we can discuss that \"what if unjustifiable rechecks are not invoked we can save X% \n",
    "## of review time and computation resources\"\n",
    "\n",
    "## observation 7,8 calculate total computation time from scenario 2,3,4 \n",
    "## then calculate time before recheck [both waiting and computation] and after recheck\n",
    "## both computation_time and waiting_time after recheck already compute then we just calculate before recheck\n",
    "cost_comparison_df = recheck_df.copy()\n",
    "cost_comparison_df.reset_index(inplace=True)\n",
    "cost_comparison_keys = cost_comparison_df['key'].tolist()\n",
    "\n",
    "for key, group in tqdm(df.groupby(['change_id','revision_number'])):    \n",
    "    \n",
    "    if key not in cost_comparison_keys:\n",
    "        continue\n",
    "    \n",
    "    cost_comparison_index = cost_comparison_keys.index(key)\n",
    "    \n",
    "    computation_time = 0\n",
    "    max_time = 0\n",
    "    start_time = ''\n",
    "    end_time = ''\n",
    "\n",
    "    for ind,col in group.iterrows():\n",
    "        \n",
    "        if col['is_bot']:\n",
    "            try:\n",
    "                bot = re.findall(r'((?:success|failure|aborted) in(?: \\w+?)*s)',col['message'],re.IGNORECASE)\n",
    "                bot_time = 0\n",
    "                for i in bot:\n",
    "                    bot_time += get_second(i.split(' in ')[1])\n",
    "                    if max_time < get_second(i.split(' in ')[1]):\n",
    "                        max_time = get_second(i.split(' in ')[1])\n",
    "                computation_time += bot_time\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if 'recheck' in col['message'].lower() and col['is_bot'] == False:\n",
    "            break\n",
    "        \n",
    "        time = col['created_at']\n",
    "                \n",
    "        if not start_time:\n",
    "            start_time = time\n",
    "            \n",
    "        if not end_time or time > end_time:\n",
    "            end_time = time\n",
    "\n",
    "                \n",
    "    cost_comparison_df.at[cost_comparison_index, 'before_recheck_computation_time'] = computation_time\n",
    "    cost_comparison_df.at[cost_comparison_index, 'before_recheck_waiting_time'] = max_time\n",
    "    try:\n",
    "        cost_comparison_df.at[cost_comparison_index, 'before_recheck_code_review_time'] = (end_time - start_time).total_seconds()\n",
    "    except:\n",
    "        cost_comparison_df.at[cost_comparison_index, 'before_recheck_code_review_time'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ab036fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T18:56:22.402138Z",
     "start_time": "2023-04-10T18:56:14.607116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ff9c50490c4570aba4feecb5f15151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "## calculate percentage computation / review time waste generate compare to before recheck case\n",
    "\n",
    "\n",
    "for ind, col in tqdm(cost_comparison_df.iterrows(),total=cost_comparison_df.shape[0]):\n",
    "    \n",
    "    try:\n",
    "        computation_percent = round((col['before_recheck_computation_time'] * 100) / (col['before_recheck_computation_time'] + col['computation_time']))\n",
    "    except:\n",
    "        computation_percent = np.nan\n",
    "        \n",
    "    try:\n",
    "        code_review_percent = round((col['before_recheck_code_review_time'] * 100) / (col['before_recheck_code_review_time'] + col['code_review_time']))\n",
    "    except:\n",
    "        code_review_percent = np.nan\n",
    "        \n",
    "    cost_comparison_df.at[ind, 'computation_percent'] = computation_percent\n",
    "    cost_comparison_df.at[ind, 'code_review_percent'] = code_review_percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e98513b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T20:03:35.739471Z",
     "start_time": "2023-04-10T20:03:35.691547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compution percent 1: 48.0\n",
      "code review percent 1: 11.0\n",
      "compution percent 2: 25.0\n",
      "code review percent 2: 5.0\n",
      "compution percent 3: 49.0\n",
      "code review percent 3: 11.0\n",
      "compution percent 4: 31.0\n",
      "code review percent 4: 6.0\n",
      "compution percent all: 31.0\n",
      "code review percent all: 6.0\n",
      "compution percent unjustified: 37.0\n",
      "code review percent unjustified: 8.0\n"
     ]
    }
   ],
   "source": [
    "for scenario in range(1,5):\n",
    "    print(f'compution percent {scenario}:',cost_comparison_df[cost_comparison_df['scenario'] == scenario]['computation_percent'].median())\n",
    "    print(f'code review percent {scenario}:',cost_comparison_df[cost_comparison_df['scenario'] == scenario]['code_review_percent'].median())\n",
    "    \n",
    "print(f'compution percent all:',cost_comparison_df[cost_comparison_df['scenario'] == scenario]['computation_percent'].median())\n",
    "print(f'code review percent all:',cost_comparison_df[cost_comparison_df['scenario'] == scenario]['code_review_percent'].median())\n",
    "    \n",
    "print(f'compution percent unjustified:',cost_comparison_df[cost_comparison_df['scenario'].isin([2,3,4])]['computation_percent'].median())\n",
    "print(f'code review percent unjustified:',cost_comparison_df[cost_comparison_df['scenario'].isin([2,3,4])]['code_review_percent'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47bcfda4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T19:52:41.102092Z",
     "start_time": "2023-04-10T19:52:40.765956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225863\n",
      "41707.98268862098\n",
      "1093104.9983264192\n"
     ]
    }
   ],
   "source": [
    "print(len(patch_output))\n",
    "patch_tup = list()\n",
    "\n",
    "for key in patch_output:    \n",
    "    patch_tup.append((patch_output[key]['computation_time'], patch_output[key]['waiting_time'], patch_output[key]['code_review_time']))\n",
    "patch_df = pd.DataFrame(patch_tup, columns=['computation_time', 'waiting_time', 'code_review_time'])\n",
    "\n",
    "patch_df['scenario'] = 'without_recheck'\n",
    "print(patch_df['computation_time'].mean())\n",
    "print(patch_df['code_review_time'].mean())                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d22182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T22:24:52.630006Z",
     "start_time": "2023-02-22T22:24:51.819635Z"
    }
   },
   "outputs": [],
   "source": [
    "## try rain cloud\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#sns.set(style=\"darkgrid\")\n",
    "#sns.set(style=\"whitegrid\")\n",
    "#sns.set_style(\"white\")\n",
    "sns.set(style=\"whitegrid\",font_scale=2)\n",
    "import matplotlib.collections as clt\n",
    "import ptitprince as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b3a00c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T22:26:21.903506Z",
     "start_time": "2023-02-22T22:24:52.632127Z"
    }
   },
   "outputs": [],
   "source": [
    "# computation_time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statannotations.Annotator import Annotator\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "f, ax = plt.subplots(4,1,sharex=True,figsize=(4,6))\n",
    "\n",
    "ort = \"h\"; pal = \"Set2\"; sigma = .2\n",
    "time = 'computation_time'\n",
    "\n",
    "# plot_df = recheck_df[['scenario',time]].copy()\n",
    "# plot_df['scenario'] = 'All'\n",
    "\n",
    "plot_df = pd.DataFrame()\n",
    "for i in range(1,5):\n",
    "    temp_df = recheck_df[recheck_df['scenario'] == i][['scenario', time]]\n",
    "    plot_df = pd.concat([plot_df, temp_df], ignore_index=True)\n",
    "\n",
    "plot_df['scenario'] = plot_df['scenario'].astype(str)\n",
    "    \n",
    "for i in range(len(plot_df['scenario'].unique())):\n",
    "    name_list = plot_df['scenario'].unique()               \n",
    "    temp_df = plot_df[plot_df['scenario'] == name_list[i]]\n",
    "    temp_df = pd.concat([patch_df[['scenario', time]], temp_df], ignore_index=True)\n",
    "    temp_df[time] = temp_df[time] / 3600\n",
    "    \n",
    "    #     swarm_plot = sns.boxplot(ax=ax[i], data=temp_df, y='scenario', x=time, showfliers = False)\n",
    "        \n",
    "    swarm_plot=pt.half_violinplot(ax=ax[i], data=temp_df, y='scenario', x=time, palette = pal, bw = .2, cut = 0.,\n",
    "                          scale = \"area\", width = .6, inner = None, orient = ort)\n",
    "    swarm_plot=sns.stripplot(ax=ax[i], data=temp_df, y='scenario', x=time, palette = pal, edgecolor = \"white\",\n",
    "                     size = 3, jitter = 1, zorder = 0, orient = ort,)\n",
    "    swarm_plot=sns.boxplot(ax=ax[i], data=temp_df, y='scenario', x=time, color = \"black\", width = .15, zorder = 10,\\\n",
    "                showcaps = True, boxprops = {'facecolor':'none', \"zorder\":10},\\\n",
    "                showfliers=False, whiskerprops = {'linewidth':2, \"zorder\":10},\\\n",
    "                   saturation = 1, orient = ort)\n",
    "    \n",
    "    label_title = ['Justifiable', 'Changed outcome multiple rechecks', 'Unchanged outcome single recheck', 'Unchanged outcome multiple rechecks']\n",
    "    swarm_plot.set_yticklabels(['Without recheck', label_title[i]])\n",
    "    \n",
    "    ax[i].set(xscale=\"log\")\n",
    "    ax[i].set_xlabel(\"\")\n",
    "    ax[i].set_ylabel(\"\")    \n",
    "    \n",
    "ax[3].set_xlabel(\"Durations (log hr)\")    \n",
    "# put stats in graph\n",
    "\n",
    "for i in range(len(plot_df['scenario'].unique())):\n",
    "    name_list = plot_df['scenario'].unique()\n",
    "    temp_df = plot_df[plot_df['scenario'] == name_list[i]]\n",
    "    temp_df = pd.concat([patch_df[['scenario', time]], temp_df], ignore_index=True)\n",
    "    temp_df[time] = temp_df[time] / 3600\n",
    "\n",
    "    pairs = [('without_recheck',name_list[i])]\n",
    "    \n",
    "    annot = Annotator(ax=ax[i], pairs=pairs, data=temp_df, y='scenario', x=time,orient='h')\n",
    "    annot.configure(test='Mann-Whitney', text_format='star', loc='outside')\n",
    "    annot.apply_test().annotate()\n",
    "\n",
    "fig = swarm_plot.get_figure()\n",
    "fig.savefig(f'../fig/RQ3_{time}.pdf', format='pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63017b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T22:27:51.621853Z",
     "start_time": "2023-02-22T22:26:21.905770Z"
    }
   },
   "outputs": [],
   "source": [
    "# code_review_time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "f, ax = plt.subplots(4,1,sharex=True,figsize=(4,6))\n",
    "ax = ax.flatten()\n",
    "# f.delaxes(ax[5])\n",
    "\n",
    "ort = \"h\"; pal = \"Set2\"; sigma = .2\n",
    "time = 'code_review_time'\n",
    "\n",
    "plot_df = pd.DataFrame()\n",
    "for i in range(1,5):\n",
    "    temp_df = recheck_df[recheck_df['scenario'] == i][['scenario', time]]\n",
    "    plot_df = pd.concat([plot_df, temp_df], ignore_index=True)\n",
    "    \n",
    "plot_df['scenario'] = plot_df['scenario'].astype(str)\n",
    "\n",
    "for i in range(len(plot_df['scenario'].unique())):\n",
    "        \n",
    "    name_list = plot_df['scenario'].unique()               \n",
    "    temp_df = plot_df[plot_df['scenario'] == name_list[i]]\n",
    "    temp_df = pd.concat([patch_df[['scenario', time]], temp_df], ignore_index=True)\n",
    "    \n",
    "    temp_df[time] = temp_df[time] / 3600\n",
    "        \n",
    "    swarm_plot=pt.half_violinplot(ax=ax[i], data=temp_df, y='scenario', x=time, palette = pal, bw = .2, cut = 0.,\n",
    "                          scale = \"area\", width = .6, inner = None, orient = ort)\n",
    "    swarm_plot=sns.stripplot(ax=ax[i], data=temp_df, y='scenario', x=time, palette = pal, edgecolor = \"white\",\n",
    "                     size = 3, jitter = 1, zorder = 0, orient = ort,)\n",
    "    swarm_plot=sns.boxplot(ax=ax[i], data=temp_df, y='scenario', x=time, color = \"black\", width = .15, zorder = 10,\\\n",
    "                showcaps = True, boxprops = {'facecolor':'none', \"zorder\":10},\\\n",
    "                showfliers=False, whiskerprops = {'linewidth':2, \"zorder\":10},\\\n",
    "                   saturation = 1, orient = ort)\n",
    "    \n",
    "    label_title = ['Justifiable', 'Changed outcome multiple rechecks', 'Unchanged outcome single recheck', 'Unchanged outcome multiple rechecks']\n",
    "    swarm_plot.set_yticklabels(['Without recheck', label_title[i]])\n",
    "    ax[i].set(xscale=\"log\")\n",
    "               \n",
    "    ax[i].set_xlabel(\"\")\n",
    "    ax[i].set_ylabel(\"\")\n",
    "\n",
    "ax[3].set_xlabel(\"Durations (log hr)\")    \n",
    "\n",
    "# put stats in graph\n",
    "\n",
    "for i in range(len(plot_df['scenario'].unique())):\n",
    "    name_list = plot_df['scenario'].unique()\n",
    "    temp_df = plot_df[plot_df['scenario'] == name_list[i]]\n",
    "    temp_df = pd.concat([patch_df[['scenario', time]], temp_df], ignore_index=True)\n",
    "    temp_df[time] = temp_df[time] / 3600\n",
    "\n",
    "    pairs = [('without_recheck',name_list[i])]\n",
    "    \n",
    "    annot = Annotator(ax=ax[i], pairs=pairs, data=temp_df, y='scenario', x=time,orient='h')\n",
    "    annot.configure(test='Mann-Whitney', text_format='star', loc='outside')\n",
    "    annot.apply_test().annotate()\n",
    "\n",
    "fig = swarm_plot.get_figure()\n",
    "fig.savefig(f'../fig/RQ3_{time}.pdf', format='pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343eab38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T22:27:52.472840Z",
     "start_time": "2023-02-22T22:27:51.624103Z"
    }
   },
   "outputs": [],
   "source": [
    "## criff-delta\n",
    "\n",
    "from cliffs_delta import cliffs_delta\n",
    "\n",
    "for scenario in sorted(recheck_df['scenario'].unique()):\n",
    "    scenario_df = recheck_df[recheck_df['scenario'] == scenario]\n",
    "    \n",
    "    d, res = cliffs_delta(scenario_df['code_review_time'], patch_df['code_review_time'])\n",
    "    print(\"code_review_time:\",scenario, d, res)\n",
    "    d, res = cliffs_delta(scenario_df['computation_time'], patch_df['computation_time'])\n",
    "    print(\"computation_time:\",scenario, d, res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b454e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T22:27:52.518829Z",
     "start_time": "2023-02-22T22:27:52.475317Z"
    }
   },
   "outputs": [],
   "source": [
    "## generate table V, VI\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "for scenario in sorted(recheck_df['scenario'].unique()):\n",
    "    scenario_df = recheck_df[recheck_df['scenario'] == scenario]\n",
    "    \n",
    "    print(f'code_review_time: {scenario}', timedelta(seconds=int(scenario_df['code_review_time'].median())))\n",
    "\n",
    "print(f'code_review_time: no recheck', timedelta(seconds=int(patch_df['code_review_time'].median())))\n",
    "print(f'code_review_time: all', timedelta(seconds=int(recheck_df['code_review_time'].median())))\n",
    "\n",
    "for scenario in sorted(recheck_df['scenario'].unique()):\n",
    "    scenario_df = recheck_df[recheck_df['scenario'] == scenario]\n",
    "    print(f'computation_time: {scenario}', timedelta(seconds=int(scenario_df['computation_time'].median())))\n",
    "\n",
    "print(f'computation_time: no recheck', timedelta(seconds=int(patch_df['computation_time'].median())))\n",
    "print(f'computation_time: all', timedelta(seconds=int(recheck_df['computation_time'].median())))\n",
    "\n",
    "for scenario in sorted(recheck_df['scenario'].unique()):\n",
    "    scenario_df = recheck_df[recheck_df['scenario'] == scenario]\n",
    "    print(f'waiting_time: {scenario}', timedelta(seconds=int(scenario_df['waiting_time'].median())))\n",
    "print(f'waiting_time: all', timedelta(seconds=int(recheck_df['waiting_time'].median())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58a5386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T22:27:52.538152Z",
     "start_time": "2023-02-22T22:27:52.520711Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "# computation time\n",
    "\n",
    "for i in range(1,5):\n",
    "    temp_df = recheck_df[(recheck_df['scenario'] == i)]\n",
    "    print(f'computation time {i}: {timedelta(seconds=int(temp_df[\"computation_time\"].sum()))}')\n",
    "\n",
    "print(f'computation time All: {timedelta(seconds=int(recheck_df[\"computation_time\"].sum()))}')\n",
    "        \n",
    "# waiting time\n",
    "\n",
    "for i in range(1,5):\n",
    "    temp_df = recheck_df[(recheck_df['scenario'] == i)]    \n",
    "    print(f'waiting time {i}: {timedelta(seconds=int(temp_df[\"waiting_time\"].sum()))}')\n",
    "\n",
    "print(f'waiting time All: {timedelta(seconds=int(recheck_df[\"waiting_time\"].sum()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3dc33f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T22:27:52.544620Z",
     "start_time": "2023-02-22T22:27:52.540244Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'waiting time All: {timedelta(seconds=int(patch_df[\"computation_time\"].sum()))}')\n",
    "print(f'waiting time All: {timedelta(seconds=int(patch_df[\"code_review_time\"].sum()))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9387ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
